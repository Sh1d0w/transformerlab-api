services:
  transformerlab-api:
    image: transformerlab-api:latest
    build:
      dockerfile: ./Dockerfile.cuda
      context: .
      args:
        TFL_HOME_DIR: /transformerlab
    container_name: transformerlab-api
    volumes:
      - ./workspace:/transformerlab/workspace

    ports:
      - "8338:8338"
    ipc: host
    tty: true
#    shm_size: '16gb'
    stdin_open: true
#    command: bash
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: "all"
            capabilities: [gpu]
    restart: unless-stopped
