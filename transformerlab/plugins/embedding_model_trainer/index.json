{
    "name": "Embedding Model Trainer",
    "uniqueId": "embedding_model_trainer",
    "description": "A plugin for training or fine-tuning embedding models using Sentence Transformers v3",
    "plugin-format": "python",
    "type": "trainer",
    "version": "0.0.1",
    "model_architectures": [
        "MLX",
        "CohereForCausalLM",
        "DeepseekV2ForCausalLM",
        "GemmaForCausalLM",
        "Gemma2ForCausalLM",
        "GPTBigCodeForCausalLM",
        "LlamaForCausalLM",
        "MistralForCausalLM",
        "MixtralForCausalLM",
        "PhiForCausalLM",
        "Phi3ForCausalLM",
        "Qwen2ForCausalLM",
        "SentenceTransformer"
      ],
    "git": "",
    "url": "",
    "files": [
      "main.py",
      "setup.sh"
    ],
    "setup-script": "setup.sh",
    "training_template_format": "none",
    "parameters": {
      "num_train_epochs": {
        "title": "Number of Training Epochs",
        "type": "integer",
        "default": 3,
        "minimum": 1,
        "maximum": 30
      },
      "batch_size": {
        "title": "Batch Size",
        "type": "integer",
        "default": 16,
        "minimum": 1,
        "maximum": 1024
      },
      "learning_rate": {
        "title": "Learning Rate",
        "type": "number",
        "default": 2e-5,
        "minimum": 1e-6,
        "maximum": 1e-1
      },
      "warmup_ratio": {
        "title": "Warmup Ratio",
        "type": "number",
        "default": 0.1,
        "minimum": 0.0,
        "maximum": 1.0
      },
      "fp16": {
        "title": "Use FP16",
        "type": "boolean",
        "default": true
      },
      "bf16": {
        "title": "Use BF16",
        "type": "boolean",
        "default": false
      },
      "max_samples": {
        "title": "Max Samples",
        "type": "integer",
        "default": -1,
        "minimum": -1
      },
      "log_to_wandb": {
        "title": "Log to Weights and Biases",
        "type": "boolean",
        "default": false
      }
    },
    "parameters_ui": {
      "num_train_epochs": {
        "ui:help": "Number of epochs for fine-tuning the embedding model."
      },
      "batch_size": {
        "ui:help": "Batch size per device (GPU/CPU). Larger values require more memory."
      },
      "learning_rate": {
        "ui:help": "Learning rate for the optimizer."
      },
      "warmup_ratio": {
        "ui:help": "Fraction of total steps to warm up the learning rate."
      },
      "fp16": {
        "ui:help": "Enable FP16 training for faster throughput if supported by your GPU."
      },
      "bf16": {
        "ui:help": "Enable BF16 training if your GPU supports it. Usually used on newer devices."
      },
      "max_samples": {
        "ui:help": "If set to > -1, only use that many samples from the training dataset."
      },
      "log_to_wandb": {
        "ui:help": "Whether to log training progress to Weights and Biases."
      }
    }
  }
  