{
    "name": "Embedding Model Trainer",
    "uniqueId": "embedding_model_trainer",
    "description": "A plugin for training or fine-tuning embedding models using Sentence Transformers v3",
    "plugin-format": "python",
    "type": "trainer",
    "version": "0.0.1",
    "model_architectures": [
      "BertModel",
      "SentenceTransformer",
      "DistilBertModel",
      "RobertaModel",
      "NomicBertModel",
      "AlbertModel",
      "XLMRobertaModel",
      "XLMModel",
      "XLNetModel",
      "LongformerModel",
      "MobileBertModel",
      "GteModel",
      "DebertaModel",
      "DebertaV2Model",
      "ElectraModel",
      "CamembertModel",
      "T5EncoderModel"
    ],
    "git": "",
    "url": "",
    "files": [
      "main.py",
      "setup.sh"
    ],
    "setup-script": "setup.sh",
    "training_template_format": "embedding",
    "parameters": {
      "dataset_type": {
        "title": "Dataset Type",
        "type": "string",
        "enum": [
          "anchor | positive",
          "anchor | positive | negative",
          "sentence_A | sentence_B | Score",
          "single sentences",
          "single sentences | class",
          "anchor | anchor",
          "damaged_sentence | original_sentence",
          "sentence_A | sentence_B | class",
          "anchor | positve/negative | class",
          "anchor | positive | negative_1 | negative_2 | ... | negative_n",
          "id | anchor | positive"
        ],
        "default": "text"
      },
      "loss_function": {
        "title": "Loss Function",
        "type": "string",
        "enum": [
          "BatchAllTripletLoss",
          "BatchHardSoftMarginTripletLoss",
          "BatchHardTripletLoss",
          "BatchSemiHardTripletLoss",
          "ContrastiveTensionLoss",
          "DenoisingAutoEncoderLoss",
          "ContrastiveTensionLossInBatchnegatives",
          "SoftmaxLoss",
          "MultiplenegativesRankingLoss",
          "CachedMultiplenegativesRankingLoss",
          "MultiplenegativesSymmetricRankingLoss",
          "CachedMultiplenegativesSymmetricRankingLoss",
          "MegaBatchMarginLoss",
          "GISTEmbedLoss",
          "CachedGISTEmbedLoss",
          "ContrastiveLoss",
          "OnlineContrastiveLoss",
          "CoSENTLoss",
          "AnglELoss",
          "CosineSimilarityLoss",
          "TripletLoss"
        ],
        "default": "MultiplenegativesRankingLoss"
      },
      "loss_modifier_name": {
        "title": "Loss Modifier Name",
        "type": "string",
        "enum": [
          "MatryoshkaLoss",
          "Matryoshka2dLoss",
          "AdaptiveLayerLoss",
          "None"
        ],
        "default": "MatryoshkaLoss"
      },
      "num_train_epochs": {
        "title": "Number of Training Epochs",
        "type": "integer",
        "default": 3,
        "minimum": 1,
        "maximum": 30
      },
      "batch_size": {
        "title": "Batch Size",
        "type": "integer",
        "default": 16,
        "minimum": 1,
        "maximum": 1024
      },
      "learning_rate": {
        "title": "Learning Rate",
        "type": "number",
        "default": 0.00002,
        "minimum": 0.000001,
        "maximum": 0.1
      },
      "warmup_ratio": {
        "title": "Warmup Ratio",
        "type": "number",
        "default": 0.1,
        "minimum": 0,
        "maximum": 1
      },
      "fp16": {
        "title": "Use FP16",
        "type": "boolean",
        "default": true
      },
      "bf16": {
        "title": "Use BF16",
        "type": "boolean",
        "default": false
      },
      "max_samples": {
        "title": "Max Samples",
        "type": "integer",
        "default": -1,
        "minimum": -1
      },
      "log_to_wandb": {
        "title": "Log to Weights and Biases",
        "type": "boolean",
        "default": false
      },
      "adaptor_name": {
        "title": "Adaptor Name",
        "type": "string",
        "default": "dummy"
      }
    },
    "parameters_ui": {
      "dataset_type": {
        "ui:help": "The type of dataset you are using for fine tuning the embedding model"
      },
      "loss_function": {
        "ui:help": "The loss function to use for training. Refer to the url for more details: https://sbert.net/docs/sentence_transformer/loss_overview.html"
      },
      "loss_modifier_name": {
        "ui:help": "Instil useful properties into the trained embedding model using Loss Modifiers. Refer to the url for more details: https://sbert.net/docs/sentence_transformer/loss_overview.html"
      },
      "num_train_epochs": {
        "ui:help": "Number of epochs for fine-tuning the embedding model."
      },
      "batch_size": {
        "ui:help": "Batch size per device (GPU/CPU). Larger values require more memory."
      },
      "learning_rate": {
        "ui:help": "Learning rate for the optimizer."
      },
      "warmup_ratio": {
        "ui:help": "Fraction of total steps to warm up the learning rate."
      },
      "fp16": {
        "ui:help": "Enable FP16 training for faster throughput if supported by your GPU."
      },
      "bf16": {
        "ui:help": "Enable BF16 training if your GPU supports it. Usually used on newer devices."
      },
      "max_samples": {
        "ui:help": "If set to > -1, only use that many samples from the training dataset."
      },
      "log_to_wandb": {
        "ui:help": "Whether to log training progress to Weights and Biases."
      }
    }
  }