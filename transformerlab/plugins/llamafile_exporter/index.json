{
  "name": "Llamafile Exporter",
  "uniqueId": "llamafile_exporter",
  "description": "Exports the current model to a fully contained self-executing llamafile.",
  "plugin-format": "python",
  "type": "exporter",
  "version": "0.1.5",
  "model_architectures": ["GGUF"],
  "supported_hardware_architectures": [
    "cpu",
    "cuda",
    "mlx"
  ],
  "export_architecture": "llamafile",
  "files": ["main.py", "setup.sh"],
  "setup-script": "setup.sh",
  "parameters": {}
}
