{
  "name": "Apple MLX Server",
  "uniqueId": "mlx_server",
  "description": "MLX Machine learning research on your laptop or in a data center - by Apple",
  "plugin-format": "python",
  "type": "loader",
  "version": "0.1.32",
  "supports": [
    "chat",
    "completion",
    "visualize_model",
    "model_layers",
    "rag",
    "tools",
    "template",
    "embeddings",
    "tokenize",
    "logprobs",
    "batched"
  ],
  "model_architectures": [
    "MLX",
    "CohereForCausalLM",
    "DeepseekV2ForCausalLM",
    "GemmaForCausalLM",
    "Gemma2ForCausalLM",
    "Gemma3ForCausalLM",
    "Gemma3ForConditionalGeneration",
    "GPTBigCodeForCausalLM",
    "LlamaForCausalLM",
    "MistralForCausalLM",
    "MixtralForCausalLM",
    "PhiForCausalLM",
    "Phi3ForCausalLM",
    "Qwen2ForCausalLM",
    "Qwen3ForCausalLM",
    "Qwen3MoeForCausalLM"
  ],
  "supported_hardware_architectures": ["mlx"],
  "files": ["main.py", "setup.sh"],
  "setup-script": "setup.sh",
  "parameters": {}
}
